{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Python 3, using Conda env: orthanc\n",
    "@Author : Hasan Shaikh\n",
    "@Email  : hasanshaikh3198@gmail.com\n",
    "@GitHub : https://github.com/hash123shaikh\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 1: Introduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# --------------------------------------------------- DICOM RT Structure Name Analysis Tool ---------------------------------------------------\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs a comprehensive analysis of RT structure nomenclature across \n",
    "the MAASTRO head & neck cancer dataset. It systematically extracts and catalogs structure \n",
    "names from RTSTRUCT DICOM files to establish naming conventions used in the dataset.\n",
    "\n",
    "## Clinical Context\n",
    "\n",
    "Radiation therapy structure sets (RTSTRUCT) contain contoured anatomical structures \n",
    "and treatment volumes. Naming conventions for these structures vary significantly \n",
    "across institutions, time periods, and clinical protocols. Common variations include:\n",
    "\n",
    "- Gross Tumor Volume      :   GTV, GTV-1, GTV-Primary, gtv\n",
    "- Clinical Target Volume  :   CTV, CTV-1, CTV1\n",
    "- Planning Target Volume  :   PTV, PTV-1, PTV1\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Systematically scan all patient directories in the dataset\n",
    "2. Extract RT structure names from RTSTRUCT DICOM files\n",
    "3. Generate frequency distributions for structure nomenclature\n",
    "4. Provide data-driven recommendations for structure selection algorithms\n",
    "5. Identify data quality issues and missing files\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.7+\n",
    "- pydicom (DICOM file parsing)\n",
    "- dcmrtstruct2nii (RT structure extraction)\n",
    "- Dataset organized in standardized directory structure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 2: Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module Imports and Compatibility Configuration\n",
    "\n",
    "This cell imports necessary Python libraries for file system operations,\n",
    "DICOM file parsing, and RT structure extraction. A compatibility patch\n",
    "ensures backward compatibility with both legacy and current pydicom versions.\n",
    "\n",
    "Libraries:\n",
    "\n",
    "- os                       : Operating system interface for path operations\n",
    "- glob                     : Unix-style pathname pattern expansion\n",
    "- pydicom                  : DICOM standard implementation for medical imaging\n",
    "- dcmrtstruct2nii          : Specialized library for RT structure extraction\n",
    "- collections.defaultdict  : Efficient counting and aggregation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "from collections import defaultdict\n",
    "\n",
    "# Backward compatibility patch for pydicom API changes\n",
    "# Versions >=1.0 renamed read_file() to dcmread()\n",
    "if not hasattr(pydicom, \"read_file\"):\n",
    "    pydicom.read_file = pydicom.dcmread\n",
    "\n",
    "from dcmrtstruct2nii import list_rt_structs\n",
    "\n",
    "print(\"Status: All required libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 3: Dataset Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset Path Configuration\n",
    "\n",
    "Define the root directory containing the MAASTRO dataset. The expected \n",
    "directory structure follows standardized medical imaging organization:\n",
    "\n",
    "Expected Structure:\n",
    "  MAASTRO Dataset/\n",
    "  ├── HN1-001/\n",
    "  │   ├── RTSTRUCT/          # RT structure set DICOM files\n",
    "  │   ├── CT/                # CT imaging series\n",
    "  ├── HN1-002/\n",
    "  └── ...\n",
    "\n",
    "Configuration Notes:\n",
    "- Relative paths are resolved from the notebook's working directory\n",
    "- Absolute paths provide more robust file system references\n",
    "- Update base_dir to match your local directory structure\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset root directory - modify as needed\n",
    "base_dir = \"./MAASTRO Dataset/Images\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATASET CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nConfigured dataset path: {os.path.abspath(base_dir)}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(\"\\nNote: Verify base_dir matches your local directory structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 4: Dataset Path Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset Accessibility Verification\n",
    "\n",
    "Performs preliminary validation to ensure:\n",
    "1. The specified dataset path exists on the file system\n",
    "2. The directory contains accessible subdirectories (patient folders)\n",
    "3. Basic dataset structure conforms to expected organization\n",
    "\n",
    "This validation step prevents downstream errors by failing early with\n",
    "actionable error messages if the dataset cannot be accessed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATASET PATH VALIDATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Verify dataset directory exists\n",
    "if not os.path.exists(base_dir):\n",
    "    error_msg = f\"\"\"\n",
    "    Dataset path not found: {os.path.abspath(base_dir)}\n",
    "    \n",
    "    Verification checklist:\n",
    "    1. Confirm dataset directory name matches exactly (case-sensitive on Unix)\n",
    "    2. Verify current working directory: {os.getcwd()}\n",
    "    3. Consider using absolute path for unambiguous reference\n",
    "    4. Check file system permissions allow read access\n",
    "    \"\"\"\n",
    "    print(error_msg)\n",
    "    raise FileNotFoundError(f\"Dataset not accessible at: {base_dir}\")\n",
    "\n",
    "print(\"Status: Dataset path validated successfully\")\n",
    "\n",
    "# Enumerate patient directories\n",
    "patient_folders = sorted([\n",
    "    d for d in os.listdir(base_dir) \n",
    "    if os.path.isdir(os.path.join(base_dir, d))\n",
    "])\n",
    "\n",
    "print(f\"Patient directories identified: {len(patient_folders)}\")\n",
    "\n",
    "if len(patient_folders) > 0:\n",
    "    print(f\"\\nSample patient IDs (first 5): {patient_folders[:5]}\")\n",
    "    if len(patient_folders) > 5:\n",
    "        print(f\"Additional patients: {len(patient_folders) - 5}\")\n",
    "else:\n",
    "    print(\"Warning: No patient subdirectories detected in dataset path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 5: RT Structure Extraction and Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Primary Data Collection: RT Structure Name Extraction\n",
    "\n",
    "This cell implements the core analysis algorithm:\n",
    "\n",
    "Algorithm Overview:\n",
    "1. Iterate through all patient directories in the dataset\n",
    "2. Locate RTSTRUCT subdirectory (case-insensitive search)\n",
    "3. Identify DICOM files within RTSTRUCT directory\n",
    "4. Extract structure names using dcmrtstruct2nii library\n",
    "5. Aggregate structure frequency statistics\n",
    "6. Classify processing outcomes (success/failure/missing data)\n",
    "\n",
    "Data Structures:\n",
    "- structure_count: Dictionary mapping structure names to occurrence frequency\n",
    "- patients_with_structures: List of successfully processed (patient_id, structures) tuples\n",
    "- patients_with_errors: List of (patient_id, error_message) for failed cases\n",
    "- patients_without_rtstruct: List of patient IDs lacking RTSTRUCT directory\n",
    "- patients_without_dcm: List of patient IDs with empty RTSTRUCT directory\n",
    "\n",
    "Error Handling:\n",
    "Exceptions during DICOM parsing are caught and logged, allowing the analysis\n",
    "to continue despite individual file corruption or format issues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RT STRUCTURE EXTRACTION ANALYSIS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Initialize data collection structures\n",
    "structure_count = defaultdict(int)\n",
    "patients_with_structures = []\n",
    "patients_with_errors = []\n",
    "patients_without_rtstruct = []\n",
    "patients_without_dcm = []\n",
    "\n",
    "# Analysis configuration\n",
    "total_patients = len(patient_folders)\n",
    "print(f\"Initiating analysis of {total_patients} patient records\\n\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Main processing loop\n",
    "for i, patient_id in enumerate(patient_folders, 1):\n",
    "    patient_path = os.path.join(base_dir, patient_id)\n",
    "    \n",
    "    # Step 1: Identify RTSTRUCT directory (case-insensitive)\n",
    "    # Rationale: Different systems may use varying case conventions\n",
    "    subdirs = [\n",
    "        d for d in os.listdir(patient_path) \n",
    "        if os.path.isdir(os.path.join(patient_path, d))\n",
    "    ]\n",
    "    subdirs_lower = {d.lower(): d for d in subdirs}\n",
    "    \n",
    "    # Verify RTSTRUCT directory existence\n",
    "    if \"rtstruct\" not in subdirs_lower:\n",
    "        print(f\"[{i:3d}] {patient_id}: RTSTRUCT directory not found\")\n",
    "        patients_without_rtstruct.append(patient_id)\n",
    "        continue\n",
    "    \n",
    "    rtstruct_folder = os.path.join(patient_path, subdirs_lower[\"rtstruct\"])\n",
    "    \n",
    "    # Step 2: Locate DICOM files\n",
    "    dcm_files = glob.glob(os.path.join(rtstruct_folder, \"*.dcm\"))\n",
    "    \n",
    "    if not dcm_files:\n",
    "        print(f\"[{i:3d}] {patient_id}: No DICOM files in RTSTRUCT directory\")\n",
    "        patients_without_dcm.append(patient_id)\n",
    "        continue\n",
    "    \n",
    "    # Step 3: Extract structure names\n",
    "    try:\n",
    "        # list_rt_structs() returns list of structure names from DICOM header\n",
    "        structures = list_rt_structs(dcm_files[0])\n",
    "        \n",
    "        print(f\"[{i:3d}] {patient_id}: {structures}\")\n",
    "        \n",
    "        # Aggregate structure frequency\n",
    "        for struct in structures:\n",
    "            structure_count[struct] += 1\n",
    "        \n",
    "        patients_with_structures.append((patient_id, structures))\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_summary = str(e)[:80]  # Truncate for readability\n",
    "        print(f\"[{i:3d}] {patient_id}: Processing error - {error_summary}\")\n",
    "        patients_with_errors.append((patient_id, str(e)))\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(f\"\\nAnalysis complete: Processed {len(patients_with_structures)} patients successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 6: Statistical Summary and Data Quality Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Descriptive Statistics and Data Quality Assessment\n",
    "\n",
    "This cell generates comprehensive statistics on:\n",
    "1. Overall processing success rates\n",
    "2. Structure name frequency distributions\n",
    "3. Data completeness metrics\n",
    "4. Quality indicators\n",
    "\n",
    "Metrics Interpretation:\n",
    "- Success Rate         : Percentage of patients with successfully extracted structures\n",
    "- Structure Frequency  : Number of patients containing each structure\n",
    "- Coverage Percentage  : Proportion of successfully processed patients with each structure\n",
    "\n",
    "A structure appearing in >80% of patients indicates high consistency and\n",
    "reliability for use in automated processing pipelines. Structures with <20%\n",
    "coverage may represent optional annotations or inconsistent naming.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Processing outcome metrics\n",
    "print(f\"\\nDataset Processing Summary:\")\n",
    "print(f\"  Total patient records: {total_patients}\")\n",
    "print(f\"  Successfully processed: {len(patients_with_structures)} \"\n",
    "      f\"({len(patients_with_structures)/total_patients*100:.1f}%)\")\n",
    "print(f\"  Missing RTSTRUCT directory: {len(patients_without_rtstruct)}\")\n",
    "print(f\"  Empty RTSTRUCT directory: {len(patients_without_dcm)}\")\n",
    "print(f\"  Processing errors: {len(patients_with_errors)}\")\n",
    "\n",
    "# Structure frequency analysis\n",
    "if structure_count:\n",
    "    print(f\"\\nRT Structure Nomenclature Analysis:\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Structure Name':<40} {'Count':>8} {'Coverage':>12}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Sort by frequency (descending)\n",
    "    sorted_structures = sorted(\n",
    "        structure_count.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for struct_name, count in sorted_structures:\n",
    "        coverage = (count / len(patients_with_structures)) * 100\n",
    "        print(f\"{struct_name:<40} {count:>8} {coverage:>11.1f}%\")\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'Unique structure identifiers:':<40} {len(structure_count):>8}\")\n",
    "    \n",
    "    # Interpretation guidelines\n",
    "    print(\"\\nInterpretation Guidelines:\")\n",
    "    print(\"  High coverage (>80%): Consistent structure, suitable for automated processing\")\n",
    "    print(\"  Medium coverage (20-80%): Variable structure, may require conditional logic\")\n",
    "    print(\"  Low coverage (<20%): Rare or optional structure, consider exclusion criteria\")\n",
    "else:\n",
    "    print(\"\\nWarning: No structure names extracted from dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 7: Error Analysis and Data Quality Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detailed Error Analysis\n",
    "\n",
    "Provides comprehensive error reporting for patients that failed processing.\n",
    "Understanding error patterns helps identify:\n",
    "- Systematic data quality issues\n",
    "- File format incompatibilities\n",
    "- Corrupted or incomplete data\n",
    "- Scanner-specific encoding problems\n",
    "\n",
    "Common Error Categories:\n",
    "1. Corrupted DICOM files (incomplete writes, transmission errors)\n",
    "2. Non-standard DICOM encoding (vendor-specific extensions)\n",
    "3. Missing required DICOM tags (incomplete RT structure sets)\n",
    "4. File system permission issues\n",
    "5. Unsupported DICOM versions or transfer syntaxes\n",
    "\n",
    "Error Rate Thresholds:\n",
    "- <5%: Acceptable data loss, individual patient exclusion recommended\n",
    "- 5-15%: Moderate concern, investigate sample errors for patterns\n",
    "- >15%: Significant data quality issue, comprehensive investigation required\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patients_with_errors:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ERROR ANALYSIS\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Display detailed error information (limited to first 10)\n",
    "    display_limit = min(10, len(patients_with_errors))\n",
    "    for patient_id, error in patients_with_errors[:display_limit]:\n",
    "        print(f\"  Patient: {patient_id}\")\n",
    "        print(f\"  Error: {error[:120]}\")  # Truncate long error messages\n",
    "        print()\n",
    "    \n",
    "    if len(patients_with_errors) > display_limit:\n",
    "        remaining = len(patients_with_errors) - display_limit\n",
    "        print(f\"  Additional {remaining} patients encountered errors (not displayed)\")\n",
    "    \n",
    "    # Error rate assessment\n",
    "    error_rate = (len(patients_with_errors) / total_patients) * 100\n",
    "    \n",
    "    print(\"\\nData Quality Assessment:\")\n",
    "    if error_rate < 5:\n",
    "        print(f\"  Error rate: {error_rate:.1f}% - Within acceptable limits\")\n",
    "        print(f\"  Recommendation: Exclude {len(patients_with_errors)} affected patients\")\n",
    "        print(f\"  Impact on statistical power: Minimal\")\n",
    "    elif error_rate < 15:\n",
    "        print(f\"  Error rate: {error_rate:.1f}% - Moderate data quality concern\")\n",
    "        print(f\"  Recommendation: Investigate error patterns before proceeding\")\n",
    "        print(f\"  Consider: Manual review of sample error cases\")\n",
    "    else:\n",
    "        print(f\"  Error rate: {error_rate:.1f}% - Significant data quality issue\")\n",
    "        print(f\"  Recommendation: Comprehensive data integrity investigation required\")\n",
    "        print(f\"  Possible causes: Dataset corruption, incorrect path, format mismatch\")\n",
    "else:\n",
    "    print(\"\\nData Quality: All patients processed successfully without errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 8: Automated Code Generation for Structure Selection** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Structure Selection Algorithm Recommendations\n",
    "\n",
    "Based on the empirical analysis of structure nomenclature in the dataset,\n",
    "this cell generates optimized structure selection code for integration into\n",
    "batch processing pipelines.\n",
    "\n",
    "Code Generation Logic:\n",
    "\n",
    "Case 1: Single Consistent Structure Name\n",
    "  - Dataset uses uniform nomenclature\n",
    "  - Generates exact string matching algorithm\n",
    "  - Highest reliability, recommended approach\n",
    "\n",
    "Case 2: Multiple Structure Variants\n",
    "  - Dataset contains naming variations (e.g., GTV, GTV-1, GTV-2)\n",
    "  - Generates three algorithmic options:\n",
    "    a) Exact match (most common variant)\n",
    "    b) Flexible substring matching (accepts any variant)\n",
    "    c) Priority-based selection (ordered preference list)\n",
    "\n",
    "Case 3: No Target Structure Found\n",
    "  - Target structure (default: GTV) not present in dataset\n",
    "  - Lists available alternative structures\n",
    "  - Provides guidance for alternative structure selection\n",
    "\n",
    "Integration Instructions:\n",
    "The generated code should replace the structure selection logic in your\n",
    "main processing script (typically lines 68-73). Ensure proper error handling\n",
    "is maintained to skip patients without the target structure.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRUCTURE SELECTION ALGORITHM RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Identify GTV-related structures (primary target for tumor segmentation)\n",
    "gtv_structures = {\n",
    "    s: structure_count[s] \n",
    "    for s in structure_count.keys() \n",
    "    if \"GTV\" in s.upper()\n",
    "}\n",
    "\n",
    "if gtv_structures:\n",
    "    print(\"\\nGross Tumor Volume (GTV) Structures Identified:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for gtv, count in sorted(gtv_structures.items(), \n",
    "                             key=lambda x: x[1], \n",
    "                             reverse=True):\n",
    "        coverage = (count / len(patients_with_structures)) * 100\n",
    "        print(f\"  Structure: '{gtv}' | Frequency: {count} patients ({coverage:.1f}% coverage)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATED CODE FOR MAIN PROCESSING SCRIPT\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nIntegration: Replace structure selection logic (lines 68-73) with code below\\n\")\n",
    "    \n",
    "    # Case 1: Single structure variant\n",
    "    if len(gtv_structures) == 1:\n",
    "        gtv_name = list(gtv_structures.keys())[0]\n",
    "        gtv_count = list(gtv_structures.values())[0]\n",
    "        \n",
    "        print(f\"# Algorithm: Exact String Matching\")\n",
    "        print(f\"# Rationale: Dataset exhibits uniform GTV nomenclature\")\n",
    "        print(f\"# Target structure: '{gtv_name}' (present in {gtv_count} patients)\")\n",
    "        print(f\"\\nselected_structure = None\")\n",
    "        print(f\"for s in structures:\")\n",
    "        print(f\"    if s.upper() == '{gtv_name.upper()}':\")\n",
    "        print(f\"        selected_structure = s\")\n",
    "        print(f\"        break\")\n",
    "        print(f\"\\n# Error handling for missing structures\")\n",
    "        print(f\"if not selected_structure:\")\n",
    "        print(f\"    print(f'Warning: GTV structure not found for patient {{patient_id}}')\")\n",
    "        print(f\"    continue  # Skip patient and proceed to next\")\n",
    "        \n",
    "    # Case 2: Multiple structure variants\n",
    "    else:\n",
    "        most_common_gtv = max(gtv_structures.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        print(f\"# Multiple GTV nomenclature variants detected\")\n",
    "        print(f\"# Select appropriate algorithm based on analysis requirements:\\n\")\n",
    "        \n",
    "        print(f\"# ALGORITHM OPTION 1: Most Common Variant\")\n",
    "        print(f\"# Target: '{most_common_gtv}' ({structure_count[most_common_gtv]} patients)\")\n",
    "        print(f\"# Use case: Maximize consistency, acceptable to exclude variant cases\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"selected_structure = None\")\n",
    "        print(f\"for s in structures:\")\n",
    "        print(f\"    if s.upper() == '{most_common_gtv.upper()}':\")\n",
    "        print(f\"        selected_structure = s\")\n",
    "        print(f\"        break\")\n",
    "        \n",
    "        print(f\"\\n\\n# ALGORITHM OPTION 2: Flexible Substring Matching\")\n",
    "        print(f\"# Accepts: Any structure containing 'GTV' substring\")\n",
    "        print(f\"# Use case: Maximize patient inclusion, heterogeneous acceptable\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"selected_structure = None\")\n",
    "        print(f\"for s in structures:\")\n",
    "        print(f\"    if 'GTV' in s.upper():\")\n",
    "        print(f\"        selected_structure = s\")\n",
    "        print(f\"        break\")\n",
    "        \n",
    "        print(f\"\\n\\n# ALGORITHM OPTION 3: Priority-Based Selection\")\n",
    "        print(f\"# Attempts structures in order of preference\")\n",
    "        print(f\"# Use case: Balance between consistency and inclusion\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"# Define priority order (most preferred first)\")\n",
    "        print(f\"gtv_priority = {list(gtv_structures.keys())}\")\n",
    "        print(f\"\\nselected_structure = None\")\n",
    "        print(f\"for preferred_gtv in gtv_priority:\")\n",
    "        print(f\"    for s in structures:\")\n",
    "        print(f\"        if s.upper() == preferred_gtv.upper():\")\n",
    "        print(f\"            selected_structure = s\")\n",
    "        print(f\"            break\")\n",
    "        print(f\"    if selected_structure:\")\n",
    "        print(f\"        break\")\n",
    "        \n",
    "        print(f\"\\n# Error handling (applies to all options)\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"if not selected_structure:\")\n",
    "        print(f\"    print(f'Warning: No GTV structure found for patient {{patient_id}}')\")\n",
    "        print(f\"    continue  # Skip patient\")\n",
    "\n",
    "else:\n",
    "    # No GTV structures found - provide alternatives\n",
    "    print(\"\\nWarning: No Gross Tumor Volume (GTV) structures detected in dataset\")\n",
    "    print(\"\\nPossible Explanations:\")\n",
    "    print(\"  1. Alternative nomenclature in use (verify structure name table)\")\n",
    "    print(\"  2. Case sensitivity mismatch (e.g., 'gtv' vs 'GTV')\")\n",
    "    print(\"  3. Dataset focuses on different anatomical structures\")\n",
    "    print(\"  4. RTSTRUCT files may not contain tumor volume annotations\")\n",
    "    \n",
    "    if structure_count:\n",
    "        print(\"\\nAvailable RT Structures in Dataset:\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # Display top 10 most common structures\n",
    "        sorted_structures = sorted(\n",
    "            structure_count.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )[:10]\n",
    "        \n",
    "        for struct_name, count in sorted_structures:\n",
    "            coverage = (count / len(patients_with_structures)) * 100\n",
    "            print(f\"  Structure: '{struct_name}' | Frequency: {count} ({coverage:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nRecommendation:\")\n",
    "        print(\"  Review structure frequency table above\")\n",
    "        print(\"  Select appropriate alternative structure for analysis\")\n",
    "        print(\"  Modify code generation target from 'GTV' to chosen structure\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS WORKFLOW COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
